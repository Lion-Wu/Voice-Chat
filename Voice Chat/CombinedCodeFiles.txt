1. 文件: Voice_ChatApp.swift
//
//  Voice_ChatApp.swift
//  Voice Chat
//
//  Created by Lion Wu on 2023/12/25.
//

import SwiftUI

@main
struct Voice_ChatApp: App {
    @StateObject private var audioManager = GlobalAudioManager.shared
    @StateObject private var settingsManager = SettingsManager.shared
    @StateObject private var chatSessionsViewModel = ChatSessionsViewModel()

    var body: some Scene {
        WindowGroup {
            ContentView()
                .environmentObject(audioManager)
                .environmentObject(settingsManager)
                .environmentObject(chatSessionsViewModel)
        }
        #if os(macOS)
        Settings {
            SettingsView()
                .environmentObject(settingsManager)
        }
        #endif
    }
}


2. 文件: ContentView.swift
//
//  ContentView.swift
//  Voice Chat
//
//  Created by Lion Wu on 2024.09.29.
//

import SwiftUI

struct ContentView: View {
    @EnvironmentObject var audioManager: GlobalAudioManager
    @EnvironmentObject var settingsManager: SettingsManager
    @EnvironmentObject var chatSessionsViewModel: ChatSessionsViewModel

    @State private var columnVisibility: NavigationSplitViewVisibility = .all
    @State private var showingSettings = false

    var body: some View {
        #if os(macOS)
        // macOS: 继续用原有的 NavigationSplitView
        NavigationSplitView(columnVisibility: $columnVisibility) {
            SidebarView(
                onConversationTap: { conversation in
                    selectConversation(conversation)
                },
                onOpenSettings: { showingSettings = true }
            )
        } detail: {
            if let selectedSession = chatSessionsViewModel.selectedSession {
                ChatView(chatSession: selectedSession)
                    .id(selectedSession.id)
            } else {
                Text("No chat selected")
                    .font(.largeTitle)
                    .foregroundColor(.gray)
                    .onAppear {
                        if chatSessionsViewModel.chatSessions.isEmpty {
                            chatSessionsViewModel.startNewSession()
                        }
                    }
            }
        }
        .sheet(isPresented: $showingSettings) {
            SettingsView()
                .environmentObject(settingsManager)
        }
        .toolbar {
            ToolbarItem {
                Button(action: {
                    startNewConversation()
                }) {
                    Image(systemName: "plus")
                }
                .help("New Chat")
                .disabled(!chatSessionsViewModel.canStartNewSession)
            }
        }
        .onAppear {
            if chatSessionsViewModel.chatSessions.isEmpty {
                chatSessionsViewModel.startNewSession()
            }
        }
        #else
        // iOS/iPadOS: 使用我们自定义的侧边栏容器
        SideMenuContainerRepresentable()
            .environmentObject(chatSessionsViewModel)
            .environmentObject(audioManager)
            .environmentObject(settingsManager)
        #endif
    }

    private func selectConversation(_ session: ChatSession) {
        chatSessionsViewModel.selectedSession = session
    }

    private func startNewConversation() {
        chatSessionsViewModel.startNewSession()
    }
}

struct ContentView_Previews: PreviewProvider {
    static var previews: some View {
        ContentView()
            .environmentObject(GlobalAudioManager.shared)
            .environmentObject(SettingsManager.shared)
            .environmentObject(ChatSessionsViewModel())
    }
}


3. 文件: ViewModel/ChatSessionsViewModel.swift
//
//  ChatSessionsViewModel.swift
//  Voice Chat
//
//  Created by Lion Wu on 2024.11.04.
//

import Foundation

class ChatSessionsViewModel: ObservableObject {
    @Published var chatSessions: [ChatSession] = []
    @Published var selectedSessionID: UUID? = nil

    var selectedSession: ChatSession? {
        get {
            guard let id = selectedSessionID else { return nil }
            return chatSessions.first(where: { $0.id == id })
        }
        set {
            selectedSessionID = newValue?.id
        }
    }

    var canStartNewSession: Bool {
        // 自行决定何时允许新会话
        if let s = selectedSession {
            return !s.messages.isEmpty
        }
        return true
    }

    init() {
        loadChatSessions()
    }

    func startNewSession() {
        let newSession = ChatSession()
        chatSessions.insert(newSession, at: 0)
        selectedSessionID = newSession.id
        saveChatSessions()
    }

    func addSession(_ session: ChatSession) {
        if !chatSessions.contains(session) {
            chatSessions.insert(session, at: 0)
            saveChatSessions()
        }
    }

    func deleteSession(at offsets: IndexSet) {
        chatSessions.remove(atOffsets: offsets)
        if !chatSessions.contains(where: { $0.id == selectedSessionID }) {
            selectedSessionID = chatSessions.first?.id
        }
        saveChatSessions()
    }

    func saveChatSessions() {
        let path = chatSessionsFileURL()
        let sessionsCopy = chatSessions
        DispatchQueue.global(qos: .background).async {
            do {
                let data = try JSONEncoder().encode(sessionsCopy)
                try data.write(to: path, options: .atomic)
            } catch {
                print("Error saving sessions: \(error)")
            }
        }
    }

    func loadChatSessions() {
        let path = chatSessionsFileURL()
        DispatchQueue.global(qos: .background).async {
            if let data = try? Data(contentsOf: path) {
                do {
                    let loaded = try JSONDecoder().decode([ChatSession].self, from: data)
                    DispatchQueue.main.async {
                        self.chatSessions = loaded
                        if self.selectedSessionID == nil {
                            self.selectedSessionID = self.chatSessions.first?.id
                        }
                        if self.chatSessions.isEmpty {
                            self.startNewSession()
                        }
                    }
                } catch {
                    print("load sessions error: \(error)")
                    DispatchQueue.main.async {
                        if self.chatSessions.isEmpty {
                            self.startNewSession()
                        }
                    }
                }
            } else {
                DispatchQueue.main.async {
                    if self.chatSessions.isEmpty {
                        self.startNewSession()
                    }
                }
            }
        }
    }

    private func chatSessionsFileURL() -> URL {
        #if os(iOS) || os(tvOS)
        let docs = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first!
        return docs.appendingPathComponent("chat_sessions.json")
        #elseif os(macOS)
        let appSupport = FileManager.default.urls(for: .applicationSupportDirectory, in: .userDomainMask).first!
        let dir = appSupport.appendingPathComponent(Bundle.main.bundleIdentifier ?? "VoiceChat")
        try? FileManager.default.createDirectory(at: dir, withIntermediateDirectories: true, attributes: nil)
        return dir.appendingPathComponent("chat_sessions.json")
        #else
        return URL(fileURLWithPath: "/tmp/chat_sessions.json")
        #endif
    }
}


4. 文件: ViewModel/ChatViewModel.swift
//
//  ChatViewModel.swift
//  Voice Chat
//
//  Created by Lion Wu on 2024/1/18.
//

import Foundation

@MainActor
class ChatViewModel: ObservableObject {
    @Published var userMessage: String = ""
    @Published var isLoading: Bool = false
    @Published var chatSession: ChatSession

    private var chatService = ChatService()
    private var settingsManager = SettingsManager.shared
    var onUpdate: (() -> Void)?

    init(chatSession: ChatSession) {
        self.chatSession = chatSession

        // Since we are on the main actor, assigning these closures is allowed.
        chatService.onMessageReceived = { [weak self] message in
            guard let self = self else { return }
            self.handleReceivedMessage(message)
        }

        chatService.onError = { [weak self] error in
            guard let self = self else { return }
            self.isLoading = false
            print("Chat error: \(error.localizedDescription)")
        }
    }

    func sendMessage() {
        let trimmedMessage = userMessage.trimmingCharacters(in: .whitespacesAndNewlines)
        guard !trimmedMessage.isEmpty else { return }

        let userMsg = ChatMessage(content: trimmedMessage, isUser: true)
        chatSession.messages.append(userMsg)
        if chatSession.title == "New Chat" {
            chatSession.title = trimmedMessage
        }
        isLoading = true
        userMessage = ""
        onUpdate?()

        // Capture current messages on the main actor
        let currentMessages = chatSession.messages
        // Perform network call on a background thread
        Task {
            self.chatService.fetchStreamedData(messages: currentMessages)
        }
    }

    private func handleReceivedMessage(_ message: ChatMessage) {
        if let lastMessage = chatSession.messages.last, !lastMessage.isUser && lastMessage.isActive {
            lastMessage.content += message.content
        } else {
            chatSession.messages.append(message)
        }
        isLoading = false
        onUpdate?()
    }

    /// 对“系统消息”执行重新生成逻辑：
    /// 1. 从指定消息开始到会话末尾的所有消息都删除
    /// 2. 根据删除后的会话，再次向服务器请求生成新的回复
    func regenerateSystemMessage(_ message: ChatMessage) {
        guard let index = chatSession.messages.firstIndex(where: { $0.id == message.id }) else {
            return
        }
        // 删除从这条系统消息到末尾的所有消息
        chatSession.messages.removeSubrange(index...)
        onUpdate?()

        // 重新请求回复
        let currentMessages = chatSession.messages
        isLoading = true
        Task {
            self.chatService.fetchStreamedData(messages: currentMessages)
        }
    }

    /// 对“用户消息”执行编辑逻辑：
    /// 1. 从指定用户消息开始到会话末尾的所有消息都删除
    /// 2. 把该用户消息的内容放到输入框里，允许用户修改后再次点击发送
    func editUserMessage(_ message: ChatMessage) {
        guard let index = chatSession.messages.firstIndex(where: { $0.id == message.id }) else {
            return
        }
        // 删除从这条用户消息到末尾的所有消息
        chatSession.messages.removeSubrange(index...)
        // 将原内容放入输入框，等待用户编辑并发送
        userMessage = message.content
        onUpdate?()
    }
}


5. 文件: ViewModel/SettingsViewModel.swift
//
//  SettingsViewModel.swift
//  Voice Chat
//
//  Created by Lion Wu on 2024.10.09.
//  Modified by [Your Name] on [Date]
//

import Foundation
import Combine

@MainActor
class SettingsViewModel: ObservableObject {
    @Published var serverAddress: String {
        didSet {
            saveServerSettings()
        }
    }
    @Published var textLang: String {
        didSet {
            saveServerSettings()
        }
    }
    @Published var refAudioPath: String {
        didSet {
            saveServerSettings()
        }
    }
    @Published var promptText: String {
        didSet {
            saveServerSettings()
        }
    }
    @Published var promptLang: String {
        didSet {
            saveServerSettings()
        }
    }

    @Published var apiURL: String {
        didSet {
            saveChatSettings()
        }
    }
    @Published var selectedModel: String {
        didSet {
            saveChatSettings()
        }
    }

    @Published var enableStreaming: Bool {
        didSet {
            saveVoiceSettings()
            // If enabling streaming, automatically set autoSplit to "cut0"
            if enableStreaming {
                autoSplit = "cut0"
            }
        }
    }
    @Published var autoSplit: String {
        didSet {
            saveModelSettings()
        }
    }
    @Published var modelId: String {
        didSet {
            saveModelSettings()
        }
    }
    @Published var language: String {
        didSet {
            saveModelSettings()
        }
    }

    private let settingsManager = SettingsManager.shared

    init() {
        let serverSettings = settingsManager.serverSettings
        self.serverAddress = serverSettings.serverAddress
        self.textLang = serverSettings.textLang
        self.refAudioPath = serverSettings.refAudioPath
        self.promptText = serverSettings.promptText
        self.promptLang = serverSettings.promptLang

        let chatSettings = settingsManager.chatSettings
        self.apiURL = chatSettings.apiURL
        self.selectedModel = chatSettings.selectedModel

        let voiceSettings = settingsManager.voiceSettings
        self.enableStreaming = voiceSettings.enableStreaming

        let modelSettings = settingsManager.modelSettings
        self.autoSplit = modelSettings.autoSplit
        self.modelId = modelSettings.modelId
        self.language = modelSettings.language
    }

    func saveServerSettings() {
        settingsManager.updateServerSettings(
            serverAddress: serverAddress,
            textLang: textLang,
            refAudioPath: refAudioPath,
            promptText: promptText,
            promptLang: promptLang
        )
    }

    func saveChatSettings() {
        settingsManager.updateChatSettings(
            apiURL: apiURL,
            selectedModel: selectedModel
        )
    }

    func saveVoiceSettings() {
        settingsManager.updateVoiceSettings(
            enableStreaming: enableStreaming
        )
    }

    func saveModelSettings() {
        settingsManager.updateModelSettings(
            modelId: modelId,
            language: language,
            autoSplit: autoSplit
        )
    }
}


6. 文件: ViewModel/VoiceViewModel.swift
//
//  VoiceViewModel.swift
//  Voice Chat
//
//  Created by Lion Wu on 2024/1/8.
//

import Foundation
import AVFoundation

@MainActor
class VoiceViewModel: ObservableObject {
    @Published var text = "Sample text."
    @Published var connectionStatus = "Waiting for connection"
    @Published var errorMessage: String?
    @Published var isLoading = false

    func setupAudioSession() {
        #if os(iOS) || os(tvOS)
        do {
            let session = AVAudioSession.sharedInstance()
            try session.setCategory(.playback, mode: .default)
            try session.setActive(true)
        } catch {
            DispatchQueue.main.async {
                self.errorMessage = "Unable to set up audio session: \(error.localizedDescription)"
            }
        }
        #endif
        // On macOS, AVAudioSession is not used. It's safe to skip.
    }
}


7. 文件: Model/GlobalAudioManager.swift
//
//  GlobalAudioManager.swift
//  Voice Chat
//
//  Created by Lion Wu on 2024.09.29.
//

import Foundation
import AVFoundation
import Combine
import NaturalLanguage

@MainActor
class GlobalAudioManager: NSObject, ObservableObject, AVAudioPlayerDelegate {
    
    static let shared = GlobalAudioManager()
    
    // MARK: - 对外公布的状态
    @Published var isShowingAudioPlayer = false
    
    /**
     isAudioPlaying 表示“用户想播放”，不代表播放器此刻必然在发声。
     - 如果 isAudioPlaying = true，但还没音频数据到，就会进入 buffering。
     - 如果 isAudioPlaying = false，则一定不发声、也不再 buffering。
     */
    @Published var isAudioPlaying = false
    
    /// currentTime: 播放进度（秒）
    @Published var currentTime: TimeInterval = 0
    
    /// isLoading: 是否在全局加载（例如第一段音频时）
    @Published var isLoading = false
    
    /// isBuffering: 是否在缓冲（= 用户想播 + 目标分片数据尚未到）
    @Published var isBuffering = false
    
    /// 出错信息
    @Published var errorMessage: String? = nil

    // MARK: - 播放器/计时器
    private var audioPlayer: AVAudioPlayer?
    private var audioTimer: Timer?

    // MARK: - 分段逻辑
    private var textSegments: [String] = []         // 切分后的文本段
    private var audioChunks: [Data?] = []           // 每段音频 (Data?)
    private var chunkDurations: [TimeInterval] = [] // 每段音频时长
    private var chunkStartTimes: [TimeInterval] = []// 每段起始时间（累加）
    private var totalDuration: TimeInterval = 0     // 所有已知段的总长

    /**
     currentChunkIndex: 下一个要请求 TTS 的文本段下标
     currentPlayingIndex: 当前播放器正在播哪个段
     */
    private var currentChunkIndex: Int = 0
    private var currentPlayingIndex: Int = 0

    /// 并发请求数和最大并发
    private var requestsInFlight: Int = 0
    private let maxRequestsInFlight = 2

    /// 正在执行的网络请求
    private var dataTasks: [URLSessionDataTask] = []

    /// 下一个预载的播放器
    private var nextAudioPlayer: AVAudioPlayer?

    // MARK: - Seek / 状态
    /// 用户刚刚 seek 到的目标时间，等待对应音频片段到达时恢复
    private var seekTime: TimeInterval?
    /// 标记正在因为 seek 而产生的缓冲
    private var isSeeking: Bool = false

    // MARK: - 配置
    private let settingsManager = SettingsManager.shared
    var mediaType: String = "wav"

    // MARK: - 1. startProcessing
    func startProcessing(text: String) {
        resetPlayer()
        isShowingAudioPlayer = true
        isLoading = true   // 首次请求音频，显示“加载中”
        currentTime = 0
        totalDuration = 0
        errorMessage = nil

        // 文本分段
        let voiceSettings = settingsManager.voiceSettings
        if voiceSettings.enableStreaming {
            self.textSegments = splitTextIntoMeaningfulSegments(text)
        } else {
            self.textSegments = [text]
        }

        let segmentCount = textSegments.count
        self.audioChunks = Array(repeating: nil, count: segmentCount)
        self.chunkDurations = Array(repeating: 0, count: segmentCount)
        self.chunkStartTimes = Array(repeating: 0, count: segmentCount)

        currentChunkIndex = 0
        currentPlayingIndex = 0
        requestsInFlight = 0

        // 用户意图：立即播放
        isAudioPlaying = true

        // 这里依然保留了「同时发送两个请求」的做法，以便并发加速。
        // 但是我们保证：只要第 0 段先回来了，就立马开始播放。
        sendNextSegment() // 请求第 0 段
        if segmentCount > 1 {
            sendNextSegment() // 请求第 1 段
        }
    }

    // MARK: - 2. 并发 TTS 请求
    private func sendNextSegment() {
        guard currentChunkIndex < textSegments.count else { return }
        guard requestsInFlight < maxRequestsInFlight else { return }

        let index = currentChunkIndex
        currentChunkIndex += 1
        requestsInFlight += 1

        let segmentText = textSegments[index]
        sendTTSRequest(for: segmentText, index: index)
    }

    private func sendTTSRequest(for segmentText: String, index: Int) {
        guard let url = constructTTSURL() else {
            DispatchQueue.main.async {
                self.isLoading = false
                self.errorMessage = "Unable to construct TTS URL"
            }
            return
        }

        // 构造参数
        let serverSettings = settingsManager.serverSettings
        let modelSettings = settingsManager.modelSettings
        let voiceSettings = settingsManager.voiceSettings

        var parameters: [String: Any] = [
            "text": segmentText,
            "text_lang": serverSettings.textLang,
            "ref_audio_path": serverSettings.refAudioPath,
            "prompt_text": serverSettings.promptText,
            "prompt_lang": serverSettings.promptLang,
            "batch_size": 1,
            "media_type": mediaType
        ]

        if voiceSettings.enableStreaming {
            parameters["text_split_method"] = "cut0"
        } else {
            parameters["text_split_method"] = modelSettings.autoSplit
        }

        guard let jsonData = try? JSONSerialization.data(withJSONObject: parameters, options: []) else {
            DispatchQueue.main.async {
                self.isLoading = false
                self.errorMessage = "Unable to serialize JSON"
            }
            return
        }

        var request = URLRequest(url: url)
        request.timeoutInterval = 60
        request.httpMethod = "POST"
        request.addValue("application/json", forHTTPHeaderField: "Content-Type")
        request.httpBody = jsonData

        let task = URLSession.shared.dataTask(with: request) { [weak self] data, response, error in
            guard let self = self else { return }
            defer {
                // 请求结束后 -1，并尝试请求下一段
                DispatchQueue.main.async {
                    self.requestsInFlight -= 1
                    self.sendNextSegment()
                }
            }

            if let error = error {
                DispatchQueue.main.async {
                    self.isLoading = false
                    self.errorMessage = "Audio request failed: \(error.localizedDescription)"
                }
                return
            }

            guard let data = data else {
                DispatchQueue.main.async {
                    self.isLoading = false
                    self.errorMessage = "No data received"
                }
                return
            }

            // 音频数据到达
            DispatchQueue.main.async {
                if index >= self.audioChunks.count { return }
                self.audioChunks[index] = data

                // 计算此段时长，更新 totalDuration
                if let player = try? AVAudioPlayer(data: data) {
                    let segDuration = player.duration
                    self.chunkDurations[index] = segDuration
                    self.calculateChunkStartTimesAndTotalDuration()
                }

                // =============================
                // 这里是关键逻辑修复：
                // ——只要第 0 段 (index == 0) 到了，就立马关闭“加载中”并尝试播放。
                // ——或者正好到了 currentPlayingIndex 这一段，也要去尝试播放。
                // =============================
                if index == 0 {
                    // 首段到 -> 即便并发还在继续，这里也先不再是 loading 了
                    self.isLoading = false

                    // 如果用户此时确实想播放，就立即播
                    if self.isAudioPlaying {
                        self.playAudioChunk(
                            at: 0,
                            fromTime: self.seekTime,
                            shouldPlay: true
                        )
                        self.seekTime = nil
                    }
                }
                else if index == self.currentPlayingIndex {
                    // 如果正好是当前要播的分片，也把 isLoading 去掉
                    self.isLoading = false

                    // 如果用户此时确实想播放
                    if self.isAudioPlaying {
                        self.playAudioChunk(
                            at: index,
                            fromTime: self.seekTime,
                            shouldPlay: true
                        )
                        self.seekTime = nil
                    }
                }

                // 如果是当前分片的下一段 -> 预加载
                if index == self.currentPlayingIndex + 1 {
                    self.prepareNextAudioChunk(at: index)
                }

                // 如果当前正在缓冲，且到达的正好是 currentPlayingIndex
                // 也要恢复播放（保证快进后能自动恢复）
                if self.isBuffering,
                   index == self.currentPlayingIndex,
                   self.isAudioPlaying
                {
                    self.playAudioChunk(
                        at: self.currentPlayingIndex,
                        fromTime: self.seekTime,
                        shouldPlay: true
                    )
                    self.seekTime = nil
                }
            }
        }
        task.resume()
        dataTasks.append(task)
    }

    // MARK: - 计算 chunkStartTimes & totalDuration
    private func calculateChunkStartTimesAndTotalDuration() {
        var cumulative: TimeInterval = 0
        for i in 0..<chunkDurations.count {
            let dur = chunkDurations[safe: i] ?? 0
            chunkStartTimes[i] = cumulative
            cumulative += dur
        }
        totalDuration = cumulative
    }

    // MARK: - 预载下一个分片
    private func prepareNextAudioChunk(at index: Int) {
        guard let chunkOpt = audioChunks[safe: index], let data = chunkOpt else { return }
        do {
            let player = try AVAudioPlayer(data: data)
            player.delegate = self
            player.prepareToPlay()
            nextAudioPlayer = player
        } catch {
            print("prepareNextAudioChunk error: \(error)")
        }
    }

    // MARK: - 播放指定分片
    @discardableResult
    private func playAudioChunk(at index: Int,
                                fromTime time: TimeInterval? = nil,
                                shouldPlay: Bool = true) -> Bool
    {
        // 若该分片越界 -> 播不动
        guard audioChunks.indices.contains(index) else { return false }

        // 若该分片数据为空 -> 需要缓冲
        guard let data = audioChunks[index] else {
            isBuffering = true
            stopAudioTimer()
            return false
        }

        // 构造播放器
        do {
            let player = try AVAudioPlayer(data: data)
            player.delegate = self
            player.prepareToPlay()

            self.audioPlayer = player

            // 在该分片内的起始位置
            let startTime: TimeInterval = {
                guard let t = time else { return 0 }
                let rel = t - (chunkStartTimes[safe: index] ?? 0)
                return max(0, min(rel, player.duration))
            }()
            player.currentTime = startTime

            if shouldPlay {
                player.play()
                startAudioTimer()
            }

            // 数据已到 -> 不再缓冲
            isBuffering = false
            isSeeking = false

            // 如果下一个分片已经到 -> 先预载
            let nextIndex = index + 1
            if let nextData = audioChunks[safe: nextIndex], nextData != nil {
                prepareNextAudioChunk(at: nextIndex)
            }

            currentPlayingIndex = index
            return true
        } catch {
            self.errorMessage = "Failed to start audio playback: \(error.localizedDescription)"
            print(errorMessage ?? "")
            return false
        }
    }

    // MARK: - 播放 / 暂停
    func togglePlayback() {
        // === 修复第二个问题点（当播放完最后一段后，再次点击“播放”，要从头开始） ===
        // 如果已经播完了（currentTime 已经到 totalDuration 或超过），
        // 则重置到起点(0段、0秒)。
        if !isAudioPlaying && currentTime >= totalDuration {
            currentPlayingIndex = 0
            currentTime = 0
        }
        
        // 若当前为“暂停” -> 切换成“想播放”
        if !isAudioPlaying {
            isAudioPlaying = true

            // 如果当前分片有数据，直接播放
            if let _ = audioChunks[safe: currentPlayingIndex] {
                playAudioChunk(
                    at: currentPlayingIndex,
                    fromTime: currentTime,
                    shouldPlay: true
                )
            } else {
                // 否则需要缓冲
                isBuffering = true
            }
        } else {
            // 若当前为“想播放” -> 切换成“暂停”
            isAudioPlaying = false
            audioPlayer?.pause()
            stopAudioTimer()
            // 不再需要缓冲
            isBuffering = false
        }
    }

    // MARK: - 快进 / 后退 15 秒
    func forward15Seconds() {
        seek(to: currentTime + 15, shouldPlay: isAudioPlaying)
    }

    func backward15Seconds() {
        seek(to: currentTime - 15, shouldPlay: isAudioPlaying)
    }

    // MARK: - seek
    func seek(to time: TimeInterval, shouldPlay: Bool = false) {
        guard totalDuration > 0 else { return }

        let newTime = max(0, min(time, totalDuration))
        currentTime = newTime

        // 找到对应分片下标
        var targetChunkIndex = 0
        for i in 0..<chunkStartTimes.count {
            if chunkStartTimes[i] > newTime {
                targetChunkIndex = max(0, i - 1)
                break
            }
            if i == chunkStartTimes.count - 1 {
                targetChunkIndex = i
            }
        }

        // 如果切换了分片，就停止当前的播放
        if targetChunkIndex != currentPlayingIndex {
            audioPlayer?.stop()
            audioPlayer = nil
            currentPlayingIndex = targetChunkIndex
        }

        // 如果分片已经下载完，则直接播放/暂停
        if let _ = audioChunks[safe: currentPlayingIndex] {
            playAudioChunk(
                at: currentPlayingIndex,
                fromTime: newTime,
                shouldPlay: shouldPlay
            )
        } else {
            // 没下载 => 缓冲
            isBuffering = shouldPlay
            isSeeking = true
            seekTime = newTime
            stopAudioTimer()
        }

        // 如果用户 seek 到了 totalDuration 且已经是最后一段，也可能直接结束
        if newTime >= totalDuration,
           currentPlayingIndex >= audioChunks.count - 1,
           audioChunks[audioChunks.count - 1] != nil
        {
            isAudioPlaying = false
            audioPlayer?.stop()
            stopAudioTimer()
            currentTime = totalDuration
        }
    }

    // MARK: - 关闭
    func closeAudioPlayer() {
        resetPlayer()
        isAudioPlaying = false
        isShowingAudioPlayer = false
        isLoading = false
    }

    // MARK: - 重置
    private func resetPlayer() {
        dataTasks.forEach { $0.cancel() }
        dataTasks.removeAll()

        audioPlayer?.stop()
        audioPlayer = nil

        nextAudioPlayer?.stop()
        nextAudioPlayer = nil

        stopAudioTimer()

        textSegments.removeAll()
        audioChunks.removeAll()
        chunkDurations.removeAll()
        chunkStartTimes.removeAll()

        currentChunkIndex = 0
        currentPlayingIndex = 0
        requestsInFlight = 0
        totalDuration = 0
        currentTime = 0

        isBuffering = false
        isSeeking = false
        seekTime = nil
        errorMessage = nil
    }

    // MARK: - 计时器
    private func startAudioTimer() {
        stopAudioTimer()
        audioTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
            Task { @MainActor in
                guard let self = self else { return }
                
                // 若在缓冲，就不更新 currentTime
                if self.isBuffering { return }
 
                if let player = self.audioPlayer {
                    let chunkStartTime = self.chunkStartTimes[safe: self.currentPlayingIndex] ?? 0
                    let localTime = player.currentTime
 
                    // 更新 currentTime
                    self.currentTime = chunkStartTime + localTime
 
                    // 如果已经播到 totalDuration，就真正结束
                    if self.currentTime >= self.totalDuration {
                        // 如果已经加载完所有分片，则停止
                        if self.allChunksLoaded() {
                            self.currentTime = self.totalDuration
                            self.isAudioPlaying = false
                            player.stop()
                            self.stopAudioTimer()
                        } else {
                            // 如果并未全部加载完，就进入缓冲等待新的音频
                            self.isBuffering = self.isAudioPlaying
                            player.pause()
                        }
                    }
                }
            }
        }
        if let audioTimer = audioTimer {
            RunLoop.current.add(audioTimer, forMode: .common)
        }
    }

    private func stopAudioTimer() {
        audioTimer?.invalidate()
        audioTimer = nil
    }

    private func allChunksLoaded() -> Bool {
        // 若还有某段是 nil，就表示没下载完
        return !audioChunks.contains(where: { $0 == nil })
    }

    // MARK: - 构造 TTS URL
    private func constructTTSURL() -> URL? {
        let serverSettings = settingsManager.serverSettings
        let urlString = "\(serverSettings.serverAddress)/tts"
        return URL(string: urlString)
    }

    // MARK: - AVAudioPlayerDelegate
    nonisolated func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
        Task { @MainActor in
            currentPlayingIndex += 1
 
            // 若已经是最后一个分片，则说明真正播完
            if currentPlayingIndex >= audioChunks.count {
                currentPlayingIndex = audioChunks.count - 1
                currentTime = totalDuration
                isAudioPlaying = false
                stopAudioTimer()
                return
            }
 
            // 如果 nextAudioPlayer 已经准备好了，就直接切过去
            if let next = nextAudioPlayer {
                audioPlayer = next
                nextAudioPlayer = nil
                audioPlayer?.delegate = self
 
                if isAudioPlaying {
                    audioPlayer?.play()
                    startAudioTimer()
                }
 
                // 再预载下一个
                let nextIndex = currentPlayingIndex + 1
                if nextIndex < audioChunks.count,
                   audioChunks[nextIndex] != nil
                {
                    prepareNextAudioChunk(at: nextIndex)
                }
            } else {
                // 没有预载好的播放器
                if let _ = audioChunks[safe: currentPlayingIndex] {
                    // 该分片数据已到 => 立即播
                    if isAudioPlaying {
                        playAudioChunk(
                            at: currentPlayingIndex,
                            fromTime: chunkStartTimes[currentPlayingIndex],
                            shouldPlay: true
                        )
                    }
                } else {
                    // 数据没到 => 进入缓冲
                    if isAudioPlaying {
                        isBuffering = true
                    }
                    stopAudioTimer()
                }
            }
        }
    }

    // MARK: - 文本拆分逻辑（和之前一样）
    private func splitTextIntoMeaningfulSegments(_ text: String, minSize: Int = 10, maxSize: Int = 100) -> [String] {
        let modifiedText = text
            .replacingOccurrences(of: #"\.\n"#, with: ". ")
            .replacingOccurrences(of: #"。\n"#, with: "")
            .replacingOccurrences(of: "\n", with: " ")

        var segments: [String] = []
        var currentSegment = ""
        let sentenceTokenizer = NLTokenizer(unit: .sentence)
        sentenceTokenizer.string = modifiedText
        var sentenceFound = false

        sentenceTokenizer.enumerateTokens(in: modifiedText.startIndex..<modifiedText.endIndex) { sentenceRange, _ in
            sentenceFound = true
            let sentence = String(modifiedText[sentenceRange])
            let language = detectLanguage(for: sentence)

            if getCount(for: currentSegment + " " + sentence, language: language) > maxSize {
                if !currentSegment.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty {
                    segments.append(currentSegment.trimmingCharacters(in: .whitespacesAndNewlines))
                    currentSegment = ""
                }
                if let splitSentences = splitSentenceAtConjunctions(sentence, language: language, minSize: minSize, maxSize: maxSize) {
                    segments.append(contentsOf: splitSentences)
                } else {
                    let subSegs = splitSentence(sentence, language: language, minSize: minSize, maxSize: maxSize)
                    segments.append(contentsOf: subSegs)
                }
            } else {
                currentSegment += " " + sentence
            }
            return true
        }

        if !sentenceFound {
            let language = detectLanguage(for: modifiedText)
            if let splitText = splitSentenceAtConjunctions(modifiedText, language: language, minSize: minSize, maxSize: maxSize) {
                segments.append(contentsOf: splitText)
            } else {
                let subSegs = splitSentence(modifiedText, language: language, minSize: minSize, maxSize: maxSize)
                segments.append(contentsOf: subSegs)
            }
        }

        if !currentSegment.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty {
            segments.append(currentSegment.trimmingCharacters(in: .whitespacesAndNewlines))
        }

        segments.removeAll { $0.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty }
        return segments
    }

    private func detectLanguage(for text: String) -> String {
        let recognizer = NLLanguageRecognizer()
        recognizer.processString(text)
        return recognizer.dominantLanguage?.rawValue ?? "unknown"
    }

    private func languageIsWordBased(_ language: String) -> Bool {
        let wordBasedLanguages = ["en", "fr", "de", "es", "it", "pt", "ru", "ja", "ko"]
        return wordBasedLanguages.contains(language)
    }

    private func wordCount(in text: String) -> Int {
        let tokenizer = NLTokenizer(unit: .word)
        tokenizer.string = text
        var count = 0
        tokenizer.enumerateTokens(in: text.startIndex..<text.endIndex) { _, _ in
            count += 1
            return true
        }
        return count
    }

    private func characterCount(in text: String) -> Int {
        return text.count
    }

    private func getCount(for text: String, language: String) -> Int {
        if languageIsWordBased(language) {
            return wordCount(in: text)
        } else {
            return characterCount(in: text)
        }
    }

    private func splitSentenceAtConjunctions(_ sentence: String, language: String, minSize: Int, maxSize: Int) -> [String]? {
        guard languageIsWordBased(language) else { return nil }

        let nsSentence = sentence as NSString
        let tagger = NSLinguisticTagger(tagSchemes: [.lexicalClass], options: 0)
        tagger.string = sentence

        var conjunctionRanges: [NSRange] = []
        tagger.enumerateTags(in: NSRange(location: 0, length: nsSentence.length),
                             unit: .word,
                             scheme: .lexicalClass)
        { tag, tokenRange, _ in
            if tag == .conjunction {
                conjunctionRanges.append(tokenRange)
            }
        }

        if conjunctionRanges.isEmpty { return nil }

        var splitSegments: [String] = []
        var lastSplitIndex = 0
        var buffer = ""

        for tokenRange in conjunctionRanges {
            let splitRange = NSRange(location: lastSplitIndex,
                                     length: tokenRange.location - lastSplitIndex)
            if splitRange.length > 0 {
                let segment = nsSentence.substring(with: splitRange).trimmingCharacters(in: .whitespacesAndNewlines)
                if !segment.isEmpty {
                    if getCount(for: buffer + " " + segment, language: language) <= maxSize {
                        buffer += " " + segment
                    } else {
                        if !buffer.isEmpty {
                            splitSegments.append(buffer.trimmingCharacters(in: .whitespacesAndNewlines))
                            buffer = ""
                        }
                        if let subSplit = splitSentenceAtConjunctions(segment, language: language, minSize: minSize, maxSize: maxSize) {
                            splitSegments.append(contentsOf: subSplit)
                        } else {
                            let further = splitSentence(segment, language: language, minSize: minSize, maxSize: maxSize)
                            splitSegments.append(contentsOf: further)
                        }
                    }
                }
            }
            let conj = nsSentence.substring(with: tokenRange).trimmingCharacters(in: .whitespacesAndNewlines)
            buffer += " " + conj
            lastSplitIndex = tokenRange.location + tokenRange.length
        }

        // 收尾
        let remainingRange = NSRange(location: lastSplitIndex,
                                     length: nsSentence.length - lastSplitIndex)
        if remainingRange.length > 0 {
            let remainingSegment = nsSentence.substring(with: remainingRange)
                .trimmingCharacters(in: .whitespacesAndNewlines)
            if !remainingSegment.isEmpty {
                if getCount(for: buffer + " " + remainingSegment, language: language) <= maxSize {
                    buffer += " " + remainingSegment
                } else {
                    if !buffer.isEmpty {
                        splitSegments.append(buffer.trimmingCharacters(in: .whitespacesAndNewlines))
                    }
                    splitSegments.append(remainingSegment)
                    buffer = ""
                }
            }
        }

        if !buffer.isEmpty {
            splitSegments.append(buffer.trimmingCharacters(in: .whitespacesAndNewlines))
        }

        var final: [String] = []
        for seg in splitSegments {
            let segCount = getCount(for: seg, language: language)
            if segCount > maxSize {
                let further = splitSentence(seg, language: language, minSize: minSize, maxSize: maxSize)
                final.append(contentsOf: further)
            } else if segCount >= minSize {
                final.append(seg)
            } else {
                if let last = final.popLast() {
                    final.append(last + " " + seg)
                } else {
                    final.append(seg)
                }
            }
        }
        return final
    }

    private func splitSentence(_ sentence: String, language: String, minSize: Int, maxSize: Int) -> [String] {
        var splitSegments: [String] = []
        if languageIsWordBased(language) {
            let words = sentence.split { $0.isWhitespace }
            var current = ""
            for w in words {
                let wordStr = String(w)
                let potential = current.isEmpty ? wordStr : "\(current) \(wordStr)"
                if wordCount(in: potential) > maxSize {
                    if !current.isEmpty {
                        splitSegments.append(current.trimmingCharacters(in: .whitespacesAndNewlines))
                        current = wordStr
                    } else {
                        splitSegments.append(wordStr)
                        current = ""
                    }
                } else {
                    current = potential
                }
            }
            if !current.isEmpty {
                splitSegments.append(current.trimmingCharacters(in: .whitespacesAndNewlines))
            }
        } else {
            // 非词汇型语言，按字符数分
            var current = ""
            for c in sentence {
                let charStr = String(c)
                let pot = current + charStr
                if characterCount(in: pot) > maxSize {
                    if !current.isEmpty {
                        splitSegments.append(current)
                        current = charStr
                    } else {
                        splitSegments.append(charStr)
                        current = ""
                    }
                } else {
                    current = pot
                }
            }
            if !current.isEmpty {
                splitSegments.append(current)
            }
        }
        return splitSegments
    }
}

// 安全下标
private extension Array {
    subscript(safe i: Int) -> Element? {
        return indices.contains(i) ? self[i] : nil
    }
}


8. 文件: Model/ChatMessage.swift
//
//  ChatMessage.swift
//  Voice Chat
//
//  Created by Lion Wu on 2024.11.04.
//

import Foundation

class ChatMessage: Identifiable, Codable, Equatable, ObservableObject {
    var id = UUID()
    @Published var content: String
    var isUser: Bool
    var isActive: Bool = true

    init(content: String, isUser: Bool, isActive: Bool = true) {
        self.content = content
        self.isUser = isUser
        self.isActive = isActive
    }

    static func == (lhs: ChatMessage, rhs: ChatMessage) -> Bool {
        return lhs.id == rhs.id
    }

    private enum CodingKeys: String, CodingKey {
        case id, content, isUser, isActive
    }

    required init(from decoder: Decoder) throws {
        let container = try decoder.container(keyedBy: CodingKeys.self)
        id = try container.decode(UUID.self, forKey: .id)
        content = try container.decode(String.self, forKey: .content)
        isUser = try container.decode(Bool.self, forKey: .isUser)
        isActive = try container.decode(Bool.self, forKey: .isActive)
    }

    func encode(to encoder: Encoder) throws {
        var container = encoder.container(keyedBy: CodingKeys.self)
        try container.encode(id, forKey: .id)
        try container.encode(content, forKey: .content)
        try container.encode(isUser, forKey: .isUser)
        try container.encode(isActive, forKey: .isActive)
    }
}


9. 文件: Model/ChatModel.swift
//
//  ChatModel.swift
//  Voice Chat
//
//  Created by Lion Wu on 2024/1/8.
//

import Foundation

struct ChatCompletionChunk: Codable {
    var id: String?
    var object: String?
    var created: Int?
    var model: String?
    var choices: [Choice]?
}

struct Choice: Codable {
    var index: Int?
    var finish_reason: String?
    var delta: Delta?
}

struct Delta: Codable {
    var role: String?
    var content: String?
}

enum ChatNetworkError: Error {
    case invalidURL
    case serverError(String)
}

@MainActor
class ChatService: NSObject, URLSessionDataDelegate {
    private var session: URLSession?
    private var dataTask: URLSessionDataTask?

    var onMessageReceived: ((ChatMessage) -> Void)?
    var onError: ((Error) -> Void)?

    override init() {
        super.init()
        let configuration = URLSessionConfiguration.default
        self.session = URLSession(configuration: configuration, delegate: self, delegateQueue: nil)
    }

    func fetchStreamedData(messages: [ChatMessage]) {
        dataTask?.cancel()

        let settingsManager = SettingsManager.shared
        let apiURLString = "\(settingsManager.chatSettings.apiURL)/v1/chat/completions"
        guard let apiURL = URL(string: apiURLString) else {
            DispatchQueue.main.async {
                self.onError?(ChatNetworkError.invalidURL)
            }
            return
        }

        var request = URLRequest(url: apiURL)
        request.httpMethod = "POST"

        let requestBody: [String: Any] = [
            "model": settingsManager.chatSettings.selectedModel,
            "stream": true,
            "messages": transformedMessagesForRequest(messages: messages)
        ]

        do {
            let jsonData = try JSONSerialization.data(withJSONObject: requestBody, options: [])
            request.httpBody = jsonData
        } catch {
            DispatchQueue.main.async {
                self.onError?(error)
            }
            return
        }

        request.addValue("application/json", forHTTPHeaderField: "Content-Type")

        dataTask = session?.dataTask(with: request)
        dataTask?.resume()
    }

    private func transformedMessagesForRequest(messages: [ChatMessage]) -> [[String: String]] {
        return messages.map { message in
            [
                "role": message.isUser ? "user" : "assistant",
                "content": message.content
            ]
        }
    }

    nonisolated func urlSession(_ session: URLSession, dataTask: URLSessionDataTask, didReceive data: Data) {
        let text = String(decoding: data, as: UTF8.self)
        text.enumerateLines { (line, _) in
            guard line.starts(with: "data: ") else { return }
            let jsonPart = line.dropFirst("data: ".count)
            if jsonPart == "[DONE]" {
                // The stream ended successfully
                return
            }
            if let data = jsonPart.data(using: .utf8),
               let decoded = try? JSONDecoder().decode(ChatCompletionChunk.self, from: data) {
                decoded.choices?.forEach { choice in
                    if let content = choice.delta?.content {
                        let message = ChatMessage(content: content, isUser: false)
                        DispatchQueue.main.async { [weak self] in
                            self?.onMessageReceived?(message)
                        }
                    }
                }
            } else {
                // Unable to decode this particular chunk. It's safer to ignore rather than fail.
            }
        }
    }

    nonisolated func urlSession(_ session: URLSession, task: URLSessionTask, didCompleteWithError error: Error?) {
        if let error = error {
            DispatchQueue.main.async {
                self.onError?(error)
            }
        }
    }
}

// MARK: - Sendable Conformance
extension ChatMessage: @unchecked Sendable {}


10. 文件: Model/ChatSession.swift
//
//  ChatSession.swift
//  Voice Chat
//
//  Created by Lion Wu on 2024.11.04.
//

import Foundation

class ChatSession: Identifiable, Codable, ObservableObject, Equatable, Hashable {
    let id: UUID
    @Published var messages: [ChatMessage]
    @Published var title: String

    init() {
        self.id = UUID()
        self.messages = []
        self.title = "New Chat"
    }

    // Equatable
    static func == (lhs: ChatSession, rhs: ChatSession) -> Bool {
        return lhs.id == rhs.id
    }

    // Hashable
    func hash(into hasher: inout Hasher) {
        hasher.combine(id)
    }

    private enum CodingKeys: String, CodingKey {
        case id, messages, title
    }

    required init(from decoder: Decoder) throws {
        let container = try decoder.container(keyedBy: CodingKeys.self)
        id = try container.decode(UUID.self, forKey: .id)
        messages = try container.decode([ChatMessage].self, forKey: .messages)
        title = try container.decode(String.self, forKey: .title)
    }

    func encode(to encoder: Encoder) throws {
        var container = encoder.container(keyedBy: CodingKeys.self)
        try container.encode(id, forKey: .id)
        try container.encode(messages, forKey: .messages)
        try container.encode(title, forKey: .title)
    }
}


11. 文件: Model/SettingsModel.swift
//
//  SettingsModel.swift
//  Voice Chat
//
//  Created by Lion Wu on 2024.09.29.
//

import Foundation

struct ServerSettings: Codable {
    var serverAddress: String
    var textLang: String
    var refAudioPath: String
    var promptText: String
    var promptLang: String
}

struct ModelSettings: Codable {
    var modelId: String
    var language: String
    var autoSplit: String
}

struct ChatSettings: Codable {
    var apiURL: String
    var selectedModel: String
}

struct VoiceSettings: Codable {
    var enableStreaming: Bool
}

@MainActor
class SettingsManager: ObservableObject {
    static let shared = SettingsManager()

    @Published var serverSettings: ServerSettings
    @Published var modelSettings: ModelSettings
    @Published var chatSettings: ChatSettings
    @Published var voiceSettings: VoiceSettings

    private init() {
        self.serverSettings = Self.loadSettings(forKey: "ServerSettings") ?? ServerSettings(
            serverAddress: "http://127.0.0.1:9880",
            textLang: "auto",
            refAudioPath: "",
            promptText: "",
            promptLang: "auto"
        )
        self.modelSettings = Self.loadSettings(forKey: "ModelSettings") ?? ModelSettings(
            modelId: "",
            language: "auto",
            autoSplit: "cut0"
        )
        self.chatSettings = Self.loadSettings(forKey: "ChatSettings") ?? ChatSettings(
            apiURL: "http://localhost:11434",
            selectedModel: ""
        )
        self.voiceSettings = Self.loadSettings(forKey: "VoiceSettings") ?? VoiceSettings(enableStreaming: true)
    }

    func updateServerSettings(serverAddress: String, textLang: String, refAudioPath: String, promptText: String, promptLang: String) {
        serverSettings.serverAddress = serverAddress
        serverSettings.textLang = textLang
        serverSettings.refAudioPath = refAudioPath
        serverSettings.promptText = promptText
        serverSettings.promptLang = promptLang
        saveServerSettings()
    }

    func updateModelSettings(modelId: String, language: String, autoSplit: String) {
        modelSettings.modelId = modelId
        modelSettings.language = language
        modelSettings.autoSplit = autoSplit
        saveModelSettings()
    }

    func updateChatSettings(apiURL: String, selectedModel: String) {
        chatSettings.apiURL = apiURL
        chatSettings.selectedModel = selectedModel
        saveChatSettings()
    }

    func updateVoiceSettings(enableStreaming: Bool) {
        voiceSettings.enableStreaming = enableStreaming
        saveVoiceSettings()
    }

    func saveServerSettings() {
        Self.saveSettings(serverSettings, forKey: "ServerSettings")
    }

    func saveModelSettings() {
        Self.saveSettings(modelSettings, forKey: "ModelSettings")
    }

    func saveChatSettings() {
        Self.saveSettings(chatSettings, forKey: "ChatSettings")
    }

    func saveVoiceSettings() {
        Self.saveSettings(voiceSettings, forKey: "VoiceSettings")
    }

    private static func saveSettings<T: Codable>(_ settings: T, forKey key: String) {
        DispatchQueue.global(qos: .background).async {
            if let data = try? PropertyListEncoder().encode(settings) {
                UserDefaults.standard.set(data, forKey: key)
            }
        }
    }

    private static func loadSettings<T: Codable>(forKey key: String) -> T? {
        if let data = UserDefaults.standard.data(forKey: key),
           let settings = try? PropertyListDecoder().decode(T.self, from: data) {
            return settings
        }
        return nil
    }
}


12. 文件: Model/Models.swift
//
//  Models.swift
//  Voice Chat
//
//  Created by Lion Wu on 2024.09.22.
//

import Foundation

struct ModelListResponse: Codable {
    let object: String
    let data: [ModelInfo]
}

struct ModelInfo: Codable {
    let id: String
    let object: String
    let created: Int?
    let owned_by: String?
}


13. 文件: Views/SettingsView.swift
//
//  SettingsView.swift
//  Voice Chat
//
//  Created by Lion Wu on 2024.09.22.
//

import SwiftUI

struct AlertError: Identifiable {
    var id = UUID()
    var message: String
}

struct SettingsView: View {
    @ObservedObject var viewModel: SettingsViewModel

    @State private var availableModels: [String] = []
    @State private var isLoadingModels = false
    @State private var errorMessage: AlertError?

    init() {
        _viewModel = ObservedObject(wrappedValue: SettingsViewModel())
    }

    @Environment(\.dismiss) private var dismiss

    var body: some View {
        #if os(macOS)
        VStack {
            ScrollView {
                VStack(alignment: .leading, spacing: 20) {
                    FormContent()
                }
                .padding()
            }
        }
        .frame(width: 500, height: 600)
        .onAppear {
            fetchAvailableModels()
        }
        .alert(item: $errorMessage) { error in
            Alert(title: Text("Error"), message: Text(error.message), dismissButton: .default(Text("OK")))
        }
        #else
        NavigationView {
            FormContent()
                .navigationBarTitle("Settings", displayMode: .inline)
                .toolbar {
                    ToolbarItem(placement: .navigationBarTrailing) {
                        Button("Close") {
                            dismiss()
                        }
                    }
                }
                .onAppear {
                    fetchAvailableModels()
                }
                .alert(item: $errorMessage) { error in
                    Alert(title: Text("Error"), message: Text(error.message), dismissButton: .default(Text("OK")))
                }
        }
        #endif
    }

    @ViewBuilder
    private func FormContent() -> some View {
        #if os(macOS)
        VStack(alignment: .leading, spacing: 20) {
            Text("Voice Generation Settings")
                .font(.headline)
            voiceGenerationSettingsSection

            Text("Chat Server Settings")
                .font(.headline)
                .padding(.top, 20)
            chatSettingsSection
        }
        #else
        Form {
            Section(header: Text("Voice Generation Settings").font(.headline)) {
                voiceGenerationSettingsSection
            }
            Section(header: Text("Chat Server Settings").font(.headline)) {
                chatSettingsSection
            }
        }
        #endif
    }

    private var voiceGenerationSettingsSection: some View {
        Group {
            LabeledTextField(label: "Server Address", placeholder: "Enter server address", text: $viewModel.serverAddress)
            LabeledTextField(label: "Text Language", placeholder: "text_lang", text: $viewModel.textLang)
            LabeledTextField(label: "Reference Audio Path", placeholder: "ref_audio_path", text: $viewModel.refAudioPath)
            LabeledTextField(label: "Prompt Text", placeholder: "prompt_text", text: $viewModel.promptText)
            LabeledTextField(label: "Prompt Language", placeholder: "prompt_lang", text: $viewModel.promptLang)

            #if os(macOS)
            HStack {
                Text("Enable Streaming")
                    .frame(width: 150, alignment: .trailing)
                Toggle("", isOn: $viewModel.enableStreaming)
            }
            HStack {
                Text("Split Method")
                    .frame(width: 150, alignment: .trailing)
                Picker("", selection: $viewModel.autoSplit) {
                    Text("cut0: No Split").tag("cut0")
                    Text("cut1: Split every 4 sentences").tag("cut1")
                    Text("cut2: Split every 50 characters").tag("cut2")
                    Text("cut3: Split by Chinese period").tag("cut3")
                    Text("cut4: Split by English period").tag("cut4")
                    Text("cut5: Split by punctuation").tag("cut5")
                }
                .disabled(viewModel.enableStreaming)
            }
            #else
            Toggle("Enable Streaming", isOn: $viewModel.enableStreaming)
            Picker("Split Method", selection: $viewModel.autoSplit) {
                Text("cut0: No Split").tag("cut0")
                Text("cut1: Split every 4 sentences").tag("cut1")
                Text("cut2: Split every 50 characters").tag("cut2")
                Text("cut3: Split by Chinese period").tag("cut3")
                Text("cut4: Split by English period").tag("cut4")
                Text("cut5: Split by punctuation").tag("cut5")
            }
            .disabled(viewModel.enableStreaming)
            #endif
        }
    }

    private var chatSettingsSection: some View {
        Group {
            LabeledTextField(label: "Chat API URL", placeholder: "Enter chat API URL", text: $viewModel.apiURL)

            if isLoadingModels {
                #if os(macOS)
                HStack {
                    ProgressView("Loading model list...")
                        .frame(maxWidth: .infinity, alignment: .leading)
                }
                #else
                ProgressView("Loading model list...")
                #endif
            } else {
                #if os(macOS)
                HStack {
                    Text("Select Model")
                        .frame(width: 150, alignment: .trailing)
                    Picker("", selection: $viewModel.selectedModel) {
                        ForEach(availableModels, id: \.self) { model in
                            Text(model).tag(model)
                        }
                    }
                }
                #else
                Picker("Select Model", selection: $viewModel.selectedModel) {
                    ForEach(availableModels, id: \.self) { model in
                        Text(model).tag(model)
                    }
                }
                #endif
            }

            #if os(macOS)
            Button(action: fetchAvailableModels) {
                Text("Refresh Model List")
            }
            .padding(.top, 10)
            #else
            Button(action: fetchAvailableModels) {
                Text("Refresh Model List")
            }
            .padding(.top, 0)
            #endif
        }
    }

    private func fetchAvailableModels() {
        guard !viewModel.apiURL.isEmpty else {
            errorMessage = AlertError(message: "API URL is empty or invalid.")
            return
        }
        isLoadingModels = true
        errorMessage = nil
        let urlString = "\(viewModel.apiURL)/v1/models"
        guard let url = URL(string: urlString) else {
            errorMessage = AlertError(message: "Invalid API URL")
            isLoadingModels = false
            return
        }

        let request = URLRequest(url: url, timeoutInterval: 30)
        URLSession.shared.dataTask(with: request) { data, response, error in
            DispatchQueue.main.async {
                self.isLoadingModels = false
                if let error = error {
                    self.errorMessage = AlertError(message: "Request failed: \(error.localizedDescription)")
                } else if let data = data,
                          let modelList = try? JSONDecoder().decode(ModelListResponse.self, from: data) {
                    self.availableModels = modelList.data.map { $0.id }
                    if !self.availableModels.contains(self.viewModel.selectedModel),
                       let firstModel = self.availableModels.first {
                        self.viewModel.selectedModel = firstModel
                    }
                } else {
                    self.errorMessage = AlertError(message: "Unable to parse model list")
                }
            }
        }.resume()
    }
}

struct LabeledTextField: View {
    var label: String
    var placeholder: String
    @Binding var text: String

    var body: some View {
        #if os(macOS)
        HStack(alignment: .center) {
            Text(label)
                .frame(width: 150, alignment: .trailing)
            TextField(placeholder, text: $text)
                .textFieldStyle(.roundedBorder)
                .frame(maxWidth: .infinity)
        }
        #else
        HStack {
            Text(label)
            Spacer()
            TextField(placeholder, text: $text)
                .multilineTextAlignment(.trailing)
        }
        #endif
    }
}

#Preview {
    SettingsView()
}


14. 文件: Views/BlurView.swift
//
//  BlurView.swift
//  Voice Chat
//
//  Created by Lion Wu on 2024.11.04.
//

import SwiftUI

#if os(macOS)
struct BlurView: NSViewRepresentable {
    func makeNSView(context: Context) -> NSVisualEffectView {
        let view = NSVisualEffectView()
        view.material = .underWindowBackground
        view.blendingMode = .behindWindow
        view.state = .active
        return view
    }

    func updateNSView(_ nsView: NSVisualEffectView, context: Context) {}
}
#else
struct BlurView: UIViewRepresentable {
    func makeUIView(context: Context) -> UIVisualEffectView {
        let effect = UIBlurEffect(style: .systemChromeMaterial)
        return UIVisualEffectView(effect: effect)
    }

    func updateUIView(_ uiView: UIVisualEffectView, context: Context) {}
}
#endif


15. 文件: Views/SidebarView.swift
//
//  SidebarView.swift
//  Voice Chat
//
//  Created by Lion Wu on 2024.11.04.
//

import SwiftUI

struct SidebarView: View {
    @EnvironmentObject var chatSessionsViewModel: ChatSessionsViewModel

    var onConversationTap: (ChatSession) -> Void
    var onOpenSettings: () -> Void

    @State private var isRenaming: Bool = false
    @State private var renamingSession: ChatSession? = nil
    @State private var newTitle: String = ""

    var body: some View {
        #if os(macOS)
        // macOS 端继续使用原 List + toolbar
        List(selection: $chatSessionsViewModel.selectedSessionID) {
            Section(header: Text("Chats")) {
                ForEach(chatSessionsViewModel.chatSessions) { session in
                    HStack {
                        Text(session.title)
                            .lineLimit(1)
                            .frame(maxWidth: .infinity, alignment: .leading)
                    }
                    .contentShape(Rectangle())
                    .onTapGesture {
                        onConversationTap(session)
                    }
                    .contextMenu {
                        Button("Rename") {
                            renameSession(session)
                        }
                        Button("Delete") {
                            if let index = chatSessionsViewModel.chatSessions.firstIndex(of: session) {
                                chatSessionsViewModel.deleteSession(at: IndexSet(integer: index))
                            }
                        }
                    }
                }
                .onDelete(perform: chatSessionsViewModel.deleteSession)
            }
        }
        .listStyle(.sidebar)
        .navigationTitle("Chats")
        .toolbar {
            ToolbarItem {
                Button(action: onOpenSettings) {
                    Image(systemName: "gearshape.fill")
                }
                .help("Settings")
            }
        }
        .sheet(isPresented: $isRenaming) {
            renameSheetView()
        }
        #else
        // iOS/iPadOS 端
        VStack(spacing: 0) {
            List(selection: $chatSessionsViewModel.selectedSessionID) {
                Section(header: Text("Chats")) {
                    ForEach(chatSessionsViewModel.chatSessions) { session in
                        HStack {
                            Text(session.title)
                                .lineLimit(1)
                                .frame(maxWidth: .infinity, alignment: .leading)
                        }
                        .contentShape(Rectangle())
                        .onTapGesture {
                            onConversationTap(session)
                        }
                        .contextMenu {
                            Button("Rename") {
                                renameSession(session)
                            }
                            Button("Delete") {
                                if let index = chatSessionsViewModel.chatSessions.firstIndex(of: session) {
                                    chatSessionsViewModel.deleteSession(at: IndexSet(integer: index))
                                }
                            }
                        }
                    }
                    .onDelete(perform: chatSessionsViewModel.deleteSession)
                }
            }
            .listStyle(.sidebar)

            Divider()

            Button(action: onOpenSettings) {
                Label("Settings", systemImage: "gearshape.fill")
                    .font(.system(.headline))
                    .padding()
            }
        }
        .sheet(isPresented: $isRenaming) {
            renameSheetView()
        }
        #endif
    }

    @ViewBuilder
    private func renameSheetView() -> some View {
        VStack(spacing: 20) {
            Text("Rename Chat")
                .font(.headline)
            TextField("New Title", text: $newTitle)
                .textFieldStyle(RoundedBorderTextFieldStyle())
                .padding()
            HStack {
                Button("Cancel") {
                    isRenaming = false
                }
                Spacer()
                Button("Save") {
                    if let session = renamingSession {
                        session.title = newTitle.trimmingCharacters(in: .whitespacesAndNewlines)
                        chatSessionsViewModel.saveChatSessions()
                    }
                    isRenaming = false
                }
            }
        }
        .padding()
        .frame(width: 300)
    }

    private func renameSession(_ session: ChatSession) {
        renamingSession = session
        newTitle = session.title
        isRenaming = true
    }
}

struct SidebarView_Previews: PreviewProvider {
    static var previews: some View {
        SidebarView(
            onConversationTap: { _ in },
            onOpenSettings: {}
        )
        .environmentObject(ChatSessionsViewModel())
    }
}


16. 文件: Views/SideMenuContainerViewController.swift
//
//  SideMenuContainerViewController.swift
//  Voice Chat
//
//  Created by Lion Wu on 2025/02/19.
//

#if os(iOS) || os(tvOS)

import SwiftUI
import UIKit

/// 这是给 iOS/iPadOS 使用的 UIViewController，
/// 内含一个左侧 Sidebar(UIHostingController) + 一个主界面(MainContentView) 的 UIHostingController，
/// 并实现手势跟手拖拽展开/收起侧边栏，且主界面不被“压缩”，而是向右偏移。
class SideMenuContainerViewController: UIViewController {

    // 侧边栏宽度
    private let sideMenuWidth: CGFloat = 280

    // 侧边栏控制器、主界面控制器
    private var sidebarHostingController: UIViewController!
    private var mainHostingController: UIViewController!

    // 侧边栏与父视图的leading约束
    private var sideMenuLeadingConstraint: NSLayoutConstraint!

    // 主界面与侧边栏trailing的约束（让它们紧挨着）
    // 注：可单独命名，也可直接写在activate里
    private var mainLeftConstraint: NSLayoutConstraint!

    // 记录当前侧边栏是否展开
    private var isMenuOpen = false

    // 拖拽时的初始 offset
    private var startMenuLeading: CGFloat = 0

    // 用于构建 SwiftUI View 的依赖（从外部传入）
    var chatSessionsViewModel: ChatSessionsViewModel!
    var audioManager: GlobalAudioManager!
    var settingsManager: SettingsManager!

    override func viewDidLoad() {
        super.viewDidLoad()

        // ============= 1) 构建并添加侧边栏 =============
        let sidebarView = SidebarView(
            onConversationTap: { [weak self] session in
                // 切换聊天
                self?.chatSessionsViewModel.selectedSession = session
                // 收起侧边栏
                self?.toggleMenu(open: false, animated: true)
            },
            onOpenSettings: { [weak self] in
                self?.presentSettings()
            }
        )
        .environmentObject(chatSessionsViewModel)

        let sidebarVC = UIHostingController(rootView: sidebarView)
        sidebarHostingController = sidebarVC

        addChild(sidebarVC)
        view.addSubview(sidebarVC.view)
        sidebarVC.view.translatesAutoresizingMaskIntoConstraints = false
        sidebarVC.didMove(toParent: self)

        // ============= 2) 构建并添加主界面 =============
        let mainView = MainContentView(
            onToggleSidebar: { [weak self] in
                guard let self = self else { return }
                self.toggleMenu(open: !self.isMenuOpen, animated: true)
            }
        )
        .environmentObject(chatSessionsViewModel)
        .environmentObject(audioManager)
        .environmentObject(settingsManager)

        let mainVC = UIHostingController(rootView: mainView)
        mainHostingController = mainVC

        addChild(mainVC)
        view.addSubview(mainVC.view)
        mainVC.view.translatesAutoresizingMaskIntoConstraints = false
        mainVC.didMove(toParent: self)

        // ============= 3) 设置AutoLayout约束 =============

        // -- 侧边栏布局 --
        // 初始时leading = -sideMenuWidth，表示完全在屏幕左侧之外
        sideMenuLeadingConstraint = sidebarVC.view.leadingAnchor.constraint(
            equalTo: view.leadingAnchor, constant: -sideMenuWidth
        )

        NSLayoutConstraint.activate([
            sideMenuLeadingConstraint,
            sidebarVC.view.topAnchor.constraint(equalTo: view.topAnchor),
            sidebarVC.view.bottomAnchor.constraint(equalTo: view.bottomAnchor),
            sidebarVC.view.widthAnchor.constraint(equalToConstant: sideMenuWidth)
        ])

        // -- 主界面布局 --
        // 主界面的leading贴在sidebar的trailing，这样二者紧挨
        // 宽度则与父视图等宽，保证不被“压缩”
        mainLeftConstraint = mainVC.view.leadingAnchor.constraint(
            equalTo: sidebarVC.view.trailingAnchor, constant: 0
        )

        NSLayoutConstraint.activate([
            mainLeftConstraint,
            mainVC.view.topAnchor.constraint(equalTo: view.topAnchor),
            mainVC.view.bottomAnchor.constraint(equalTo: view.bottomAnchor),
            mainVC.view.widthAnchor.constraint(equalTo: view.widthAnchor)
        ])

        // 默认侧边栏“关闭”（leading = -sideMenuWidth）
        isMenuOpen = false

        // ============= 4) 添加Pan手势以实现“跟手拖拽” =============
        let panGesture = UIPanGestureRecognizer(target: self, action: #selector(handlePanGesture(_:)))
        panGesture.delegate = self
        view.addGestureRecognizer(panGesture)
    }

    private func presentSettings() {
        // 弹出 SwiftUI 的 SettingsView
        let settingsView = SettingsView().environmentObject(settingsManager)
        let settingsVC = UIHostingController(rootView: settingsView)
        settingsVC.modalPresentationStyle = .formSheet
        present(settingsVC, animated: true, completion: nil)
    }

    /// 切换侧边栏展开/收起
    func toggleMenu(open: Bool, animated: Bool) {
        isMenuOpen = open
        let finalLeading = open ? 0 : -sideMenuWidth

        if animated {
            UIView.animate(withDuration: 0.3, animations: {
                self.sideMenuLeadingConstraint.constant = finalLeading
                self.view.layoutIfNeeded()
            })
        } else {
            sideMenuLeadingConstraint.constant = finalLeading
        }
    }

    @objc private func handlePanGesture(_ gesture: UIPanGestureRecognizer) {
        let translation = gesture.translation(in: view).x

        switch gesture.state {
        case .began:
            startMenuLeading = sideMenuLeadingConstraint.constant
        case .changed:
            // sideMenuLeadingConstraint 在 [-sideMenuWidth, 0]之间移动
            let newLeading = startMenuLeading + translation
            sideMenuLeadingConstraint.constant = max(-sideMenuWidth, min(0, newLeading))
        case .ended, .cancelled:
            let velocityX = gesture.velocity(in: view).x
            let currentOffset = sideMenuLeadingConstraint.constant

            // 根据惯性+当前位置判断是展开还是收起
            let shouldOpen: Bool
            if abs(velocityX) > 300 {
                // 如果速度大于某阈值，则根据速度方向判断
                shouldOpen = velocityX > 0
            } else {
                // 否则根据当前位置是否超过一半来判断
                shouldOpen = (currentOffset > -sideMenuWidth * 0.5)
            }

            toggleMenu(open: shouldOpen, animated: true)
        default:
            break
        }
    }
}

// 让其他手势（子视图的 ScrollView 等）能/不能与 panGesture 共存
extension SideMenuContainerViewController: UIGestureRecognizerDelegate {
    func gestureRecognizer(_ gestureRecognizer: UIGestureRecognizer,
                           shouldRecognizeSimultaneouslyWith otherGestureRecognizer: UIGestureRecognizer) -> Bool {
        return false
    }
}

/// SwiftUI 包装：在 iOS 下使用此 Representable 来展示自定义容器控制器
struct SideMenuContainerRepresentable: UIViewControllerRepresentable {
    @EnvironmentObject var chatSessionsViewModel: ChatSessionsViewModel
    @EnvironmentObject var audioManager: GlobalAudioManager
    @EnvironmentObject var settingsManager: SettingsManager

    func makeUIViewController(context: Context) -> SideMenuContainerViewController {
        let vc = SideMenuContainerViewController()
        vc.chatSessionsViewModel = chatSessionsViewModel
        vc.audioManager = audioManager
        vc.settingsManager = settingsManager
        return vc
    }

    func updateUIViewController(_ uiViewController: SideMenuContainerViewController, context: Context) {
        // 不需要实时更新
    }
}

#endif


17. 文件: Views/VoiceModeView.swift
//
//  VoiceModeView.swift
//  Voice Chat
//
//  Created by Lion Wu on 2025/3/9.
//

import SwiftUI
import Speech
import AVFoundation

struct VoiceModeView: View {
    // 识别完成后把结果回调给外部
    let onRecognized: (String) -> Void
    let onClose: () -> Void

    @StateObject private var speechRecognizer = SpeechRecognizerHelper()
    @State private var isMicMuted = false

    var body: some View {
        ZStack {
            Color.black.edgesIgnoringSafeArea(.all)

            VStack {
                Spacer()

                // 中间的圆形波纹（此处简化为一个静态圆）
                Circle()
                    .strokeBorder(Color.white, lineWidth: 3)
                    .frame(width: 150, height: 150)

                Spacer()

                HStack {
                    // 静音/启用按钮
                    Button(action: {
                        isMicMuted.toggle()
                        speechRecognizer.toggleMute(isMicMuted)
                    }) {
                        Image(systemName: isMicMuted ? "mic.slash.fill" : "mic.fill")
                            .font(.title)
                            .foregroundColor(.white)
                            .padding()
                    }

                    Spacer()

                    // 关闭按钮
                    Button(action: {
                        // 若已经识别到一些内容，或想要在关闭前提交，可以在这里处理
                        speechRecognizer.stopRecording()
                        onClose()
                    }) {
                        Text("关闭")
                            .foregroundColor(.white)
                            .padding()
                    }
                }
                .padding(.horizontal, 30)
                .padding(.bottom, 50)
            }
        }
        .onAppear {
            // 请求权限并开始录音
            speechRecognizer.startRecording { recognizedText in
                // 当识别到一段后，如果要立即提交：
                // 不过本例子里是把全部说完之后的一次性结果返回
                // 这里留作演示
                // print("partial recognized: \(recognizedText)")
            } onComplete: { finalText in
                // 用户停止说话，或者系统检测到长时间静音
                onRecognized(finalText)
                onClose()
            }
        }
        .onDisappear {
            // 确保离开界面时停止录音
            speechRecognizer.stopRecording()
        }
    }
}

/// 辅助类，使用苹果 Speech 框架进行语音识别
class SpeechRecognizerHelper: NSObject, ObservableObject {
    private let audioEngine = AVAudioEngine()
    private var speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "en-US")) // 可改成选定语言
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?

    private var partialResultHandler: ((String) -> Void)?
    private var completionHandler: ((String) -> Void)?

    private var isMuted = false

    /// 开始录音并实时识别
    func startRecording(onPartial: @escaping (String) -> Void,
                        onComplete: @escaping (String) -> Void) {
        partialResultHandler = onPartial
        completionHandler = onComplete

        // 请求语音识别权限
        SFSpeechRecognizer.requestAuthorization { status in
            DispatchQueue.main.async {
                guard status == .authorized else {
                    onComplete("")
                    return
                }
                self.internalStartRecording()
            }
        }
    }

    private func internalStartRecording() {
        // 如果之前有task，先取消
        recognitionTask?.cancel()
        recognitionTask = nil

        // 音频会话
        let audioSession = AVAudioSession.sharedInstance()
        do {
            // .playAndRecord 以便边播边录，这里仅演示
            try audioSession.setCategory(.playAndRecord, mode: .default, options: [])
            try audioSession.setActive(true)
        } catch {
            print("Audio session error: \(error)")
            completionHandler?("")
            return
        }

        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
        guard let recognitionRequest = recognitionRequest else {
            completionHandler?("")
            return
        }
        recognitionRequest.shouldReportPartialResults = true

        let inputNode = audioEngine.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { buffer, when in
            if !self.isMuted {
                recognitionRequest.append(buffer)
            }
        }

        audioEngine.prepare()
        do {
            try audioEngine.start()
        } catch {
            print("audioEngine couldn't start: \(error)")
            completionHandler?("")
            return
        }

        // 开始识别任务
        recognitionTask = speechRecognizer?.recognitionTask(with: recognitionRequest, resultHandler: { result, error in
            if let result = result {
                let bestString = result.bestTranscription.formattedString
                self.partialResultHandler?(bestString)

                if result.isFinal {
                    // 识别到最终结果
                    DispatchQueue.main.async {
                        self.completionHandler?(bestString)
                    }
                }
            }

            if error != nil || (result?.isFinal ?? false) {
                // 结束
                self.stopRecording()
            }
        })
    }

    /// 切换静音/启用
    func toggleMute(_ mute: Bool) {
        isMuted = mute
    }

    /// 停止录音和识别
    func stopRecording() {
        audioEngine.stop()
        audioEngine.inputNode.removeTap(onBus: 0)
        recognitionRequest?.endAudio()
        recognitionTask?.cancel()

        recognitionRequest = nil
        recognitionTask = nil
    }
}


18. 文件: Views/MainContentView.swift
//
//  MainContentView.swift
//  Voice Chat
//
//  Created by Lion Wu on 2025/2/19.
//

#if os(iOS) || os(tvOS)

import Foundation
import SwiftUI

/// iOS/iPadOS 主视图：顶部左/右按钮，下面是 ChatView
struct MainContentView: View {
    @EnvironmentObject var chatSessionsViewModel: ChatSessionsViewModel

    let onToggleSidebar: () -> Void

    var body: some View {
        ZStack(alignment: .top) {
            VStack(spacing: 0) {
                // 自定义顶部条
                HStack {
                    // 左上角按钮：打开或关闭侧边栏
                    Button(action: {
                        onToggleSidebar()
                    }) {
                        Image(systemName: "line.3.horizontal")
                            .font(.title2)
                    }

                    Spacer()

                    // 右上角按钮：新建聊天
                    Button(action: {
                        chatSessionsViewModel.startNewSession()
                    }) {
                        Image(systemName: "plus")
                            .font(.title2)
                    }
                    .disabled(currentChatIsEmpty)
                }
                .padding()
                .background(Color(UIColor.systemBackground))
                Divider()

                // 聊天区域
                if let selectedSession = chatSessionsViewModel.selectedSession {
                    ChatView(chatSession: selectedSession)
                        .id(selectedSession.id)
                } else {
                    // 若无选中会话，自动新建一个
                    Text("No chat. Creating one...")
                        .onAppear {
                            chatSessionsViewModel.startNewSession()
                        }
                }
            }
        }
        .onAppear {
            // 如果启动时没有会话，自动新建
            if chatSessionsViewModel.chatSessions.isEmpty {
                chatSessionsViewModel.startNewSession()
            }
        }
    }

    private var currentChatIsEmpty: Bool {
        guard let session = chatSessionsViewModel.selectedSession else {
            return true
        }
        return session.messages.isEmpty
    }
}

#endif


19. 文件: Views/ChatView.swift
//
//  ChatView.swift
//  Voice Chat
//
//  Created by Lion Wu on 2024/1/8.
//

import SwiftUI

struct ChatView: View {
    @EnvironmentObject var chatSessionsViewModel: ChatSessionsViewModel
    @EnvironmentObject var audioManager: GlobalAudioManager
    @StateObject private var viewModel: ChatViewModel
    @State private var textFieldHeight: CGFloat = 40
    @FocusState private var isInputFocused: Bool

    // 用于“选择文本”功能时的弹窗
    @State private var isShowingTextSelectionSheet: Bool = false
    @State private var textSelectionContent: String = ""

    init(chatSession: ChatSession) {
        _viewModel = StateObject(wrappedValue: ChatViewModel(chatSession: chatSession))
    }

    var body: some View {
        ZStack(alignment: .top) {
            VStack {
                ScrollViewReader { scrollView in
                    ScrollView {
                        LazyVStack(spacing: 10) {
                            ForEach(viewModel.chatSession.messages) { message in
                                VoiceMessageView(
                                    message: message,
                                    onSelectText: { showSelectTextSheet(with: $0) },
                                    onRegenerate: { viewModel.regenerateSystemMessage($0) },
                                    onEditUserMessage: { viewModel.editUserMessage($0) }
                                )
                                .id(message.id)
                            }
                        }
                        .padding() // 整体内边距
                        .onChange(of: viewModel.chatSession.messages.count) { _, _ in
                            scrollToBottom(scrollView: scrollView)
                        }
                    }
                    // 在 UIKit 平台上支持滚动时自动收起键盘（iOS、tvOS、watchOS）
                    #if os(iOS) || os(tvOS) || os(watchOS)
                    .scrollDismissesKeyboard(.interactively)
                    #endif
                    .onTapGesture {
                        isInputFocused = false
                    }
                }

                if viewModel.isLoading {
                    ProgressView()
                        .padding()
                }

                // 输入区域
                HStack(spacing: 8) {
                    AutoSizingTextEditor(text: $viewModel.userMessage, height: $textFieldHeight)
                        .focused($isInputFocused)
                        .frame(height: textFieldHeight)
                        .padding(.vertical, 8)
                        .padding(.horizontal, 12)

                    Button(action: {
                        viewModel.sendMessage()
                    }) {
                        Image(systemName: "arrow.up.circle.fill")
                            .font(.system(size: 30))
                            .foregroundColor(.blue)
                    }
                    .buttonStyle(PlainButtonStyle())
                    .padding(.trailing, 8)
                    .disabled(viewModel.userMessage.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty)
                }
                .background(RoundedRectangle(cornerRadius: 15).fill(Color.gray.opacity(0.1)))
                .overlay(
                    RoundedRectangle(cornerRadius: 15)
                        .stroke(Color.gray.opacity(0.3), lineWidth: 1)
                )
                .padding()
            }

            // 语音播放视图
            if audioManager.isShowingAudioPlayer {
                VStack {
                    AudioPlayerView()
                        .environmentObject(audioManager)
                    Spacer()
                }
                .transition(.move(edge: .top))
                .animation(.easeInOut, value: audioManager.isShowingAudioPlayer)
            }
        }
        #if os(macOS)
        .navigationTitle(viewModel.chatSession.title)
        #endif
        .onAppear {
            viewModel.onUpdate = { [weak viewModel, weak chatSessionsViewModel] in
                DispatchQueue.main.async {
                    guard let viewModel = viewModel, let chatSessionsViewModel = chatSessionsViewModel else { return }
                    if !chatSessionsViewModel.chatSessions.contains(viewModel.chatSession) {
                        chatSessionsViewModel.addSession(viewModel.chatSession)
                    } else {
                        chatSessionsViewModel.saveChatSessions()
                    }
                }
            }
        }
        // “选择文本”功能所用的弹出窗口
        .sheet(isPresented: $isShowingTextSelectionSheet) {
            NavigationView {
                ScrollView {
                    Text(textSelectionContent)
                        .textSelection(.enabled)
                        .padding()
                }
                .navigationTitle("选择文本")
                .toolbar {
                    #if os(macOS)
                    ToolbarItem(placement: .automatic) { // macOS 兼容
                        Button("完成") {
                            isShowingTextSelectionSheet = false
                        }
                    }
                    #else
                    ToolbarItem(placement: .navigationBarTrailing) { // iOS / iPadOS
                        Button("完成") {
                            isShowingTextSelectionSheet = false
                        }
                    }
                    #endif
                }
            }
            // iPad 下默认是 sheet，这里无需特别处理 macOS 的弹窗
        }
    }

    private func scrollToBottom(scrollView: ScrollViewProxy) {
        if let lastMessage = viewModel.chatSession.messages.last {
            withAnimation(.easeIn(duration: 0.1)) {
                scrollView.scrollTo(lastMessage.id, anchor: .bottom)
            }
        }
    }

    private func showSelectTextSheet(with text: String) {
        textSelectionContent = text
        isShowingTextSelectionSheet = true
    }
}

// MARK: - 气泡中的长按菜单及其逻辑

struct VoiceMessageView: View {
    @ObservedObject var message: ChatMessage
    @EnvironmentObject var audioManager: GlobalAudioManager

    /// 选择文本回调
    let onSelectText: (String) -> Void

    /// 重新生成回调（仅系统消息有）
    let onRegenerate: (ChatMessage) -> Void

    /// 编辑用户消息回调（仅用户消息有）
    let onEditUserMessage: (ChatMessage) -> Void

    var body: some View {
        HStack(alignment: .top, spacing: 10) {
            if message.isUser {
                Spacer()
                TextBubble(text: message.content, isUser: true)
            } else {
                // 系统消息不显示左侧头像，也不再显示额外的朗读按钮
                TextBubble(text: message.content, isUser: false)
            }
        }
        .padding(.vertical, 5)
        // 长按或右键菜单
        .contextMenu {
            Button {
                copyToClipboard(message.content)
            } label: {
                Label("复制", systemImage: "doc.on.doc")
            }
            
            Button {
                onSelectText(message.content)
            } label: {
                Label("选择文本", systemImage: "text.cursor")
            }
            
            if message.isUser {
                // 用户消息：复制、选择文本、编辑
                Button {
                    onEditUserMessage(message)
                } label: {
                    Label("编辑", systemImage: "pencil")
                }
            } else {
                // 系统消息：复制、选择文本、重新生成、朗读
                Button {
                    onRegenerate(message)
                } label: {
                    Label("重新生成", systemImage: "arrow.clockwise")
                }
                Button {
                    audioManager.startProcessing(text: message.content)
                } label: {
                    Label("朗读", systemImage: "speaker.wave.2.fill")
                }
            }
        }
    }

    private func copyToClipboard(_ text: String) {
        #if os(iOS) || os(tvOS)
        UIPasteboard.general.string = text
        #elseif os(macOS)
        let pasteboard = NSPasteboard.general
        pasteboard.declareTypes([.string], owner: nil)
        pasteboard.setString(text, forType: .string)
        #endif
    }
}

// MARK: - 输入框自适应高度

struct AutoSizingTextEditor: View {
    @Binding var text: String
    @Binding var height: CGFloat

    var body: some View {
        ZStack(alignment: .topLeading) {
            if text.isEmpty {
                Text("在这里输入消息...")
                    .foregroundColor(.gray)
                    .padding(EdgeInsets(top: 12, leading: 8, bottom: 8, trailing: 8))
                    .font(.system(size: 17))
            }

            Text(text)
                .font(.system(size: 17))
                .foregroundColor(.clear)
                .padding(8)
                .background(
                    GeometryReader { geometry in
                        Color.clear
                            .onChange(of: text) { _, _ in
                                DispatchQueue.main.async {
                                    height = geometry.size.height
                                }
                            }
                    }
                )

            TextEditor(text: $text)
                .font(.system(size: 17))
                .padding(4)
                .background(Color.clear)
        }
        .frame(height: max(height, 40))
    }
}

// MARK: - 文字气泡

struct TextBubble: View {
    let text: String
    let isUser: Bool
    @State private var isExpanded = false
    private let maxCharacters = 1000
    /// 固定左右空白（系统消息右侧、用户消息左侧）
    private let horizontalMargin: CGFloat = 40

    var body: some View {
        VStack(alignment: isUser ? .trailing : .leading) {
            // 仅用户消息需要折叠逻辑，系统消息全部显示
            Text(isUser
                 ? (isExpanded ? text : String(text.prefix(maxCharacters)) + (text.count > maxCharacters ? "..." : ""))
                 : text)
                .padding(12)
                .background(isUser ? Color.gray.opacity(0.2) : Color.clear)
                .foregroundColor(.primary)
                .clipShape(RoundedRectangle(cornerRadius: 15, style: .continuous))
                // 限制气泡宽度，让两侧各留固定空白
                .frame(maxWidth: maxWidth - horizontalMargin, alignment: isUser ? .trailing : .leading)

            if isUser && text.count > maxCharacters {
                Button(action: {
                    withAnimation {
                        isExpanded.toggle()
                    }
                }) {
                    Text(isExpanded ? "收起" : "显示完整信息")
                        .font(.caption)
                        .foregroundColor(.blue)
                        .padding(.top, 4)
                }
            }
        }
    }

    private var maxWidth: CGFloat {
        #if os(iOS) || os(tvOS)
        return UIScreen.main.bounds.width
        #elseif os(macOS)
        return NSScreen.main?.frame.width ?? 800
        #else
        return 600
        #endif
    }
}

struct ChatView_Previews: PreviewProvider {
    static var previews: some View {
        let chatSession = ChatSession()
        ChatView(chatSession: chatSession)
            .environmentObject(GlobalAudioManager.shared)
            .environmentObject(ChatSessionsViewModel())
    }
}


20. 文件: Views/AudioPlayerView.swift
//
//  AudioPlayerView.swift
//  Voice Chat
//
//  Created by Lion Wu on 2024.09.29.
//

import SwiftUI

struct AudioPlayerView: View {
    @EnvironmentObject var audioManager: GlobalAudioManager

    var body: some View {
        VStack {
            if audioManager.isLoading {
                HStack {
                    ProgressView()
                    Text("Loading...")
                        .font(.subheadline)
                    Spacer()
                    CloseButton(action: audioManager.closeAudioPlayer)
                }
                .padding()
            } else {
                HStack {
                    ControlButton(icon: "gobackward.15", action: audioManager.backward15Seconds)
                    ControlButton(icon: audioManager.isAudioPlaying ? "pause.circle.fill" : "play.circle.fill", action: audioManager.togglePlayback, isLarge: true)
                    ControlButton(icon: "goforward.15", action: audioManager.forward15Seconds)
                    Text(formatTime(audioManager.currentTime))
                        .font(.system(.body, design: .rounded))
                        .bold()
                        .padding(.leading, 8)
                        .contentTransition(.numericText())
                        .transaction { t in
                            t.animation = .default
                        }

                    if audioManager.isBuffering {
                        HStack(spacing: 5) {
                            ProgressView()
                                .scaleEffect(0.7)
                            Text("Buffering")
                                .font(.footnote)
                        }
                        .padding(.leading, 8)
                    }

                    Spacer()
                    CloseButton(action: audioManager.closeAudioPlayer)
                }
                .padding()

                if let errorMessage = audioManager.errorMessage {
                    Text(errorMessage)
                        .foregroundColor(.red)
                        .padding()
                }
            }
        }
        .background(BlurView().opacity(0.95))
        .cornerRadius(10)
        .shadow(radius: 5)
        .padding()
        .transition(.move(edge: .top))
        .animation(.easeInOut, value: audioManager.isShowingAudioPlayer)
    }

    private func formatTime(_ currentTime: TimeInterval) -> String {
        guard !currentTime.isNaN, !currentTime.isInfinite else { return "00:00" }
        let currentMinutes = Int(currentTime) / 60
        let currentSeconds = Int(currentTime) % 60
        return String(format: "%02d:%02d", currentMinutes, currentSeconds)
    }

    struct ControlButton: View {
        let icon: String
        let action: () -> Void
        var isLarge: Bool = false

        var body: some View {
            Button(action: action) {
                Image(systemName: icon)
                    .font(isLarge ? .largeTitle : .title)
            }
            .buttonStyle(PlainButtonStyle())
        }
    }

    struct CloseButton: View {
        let action: () -> Void

        var body: some View {
            Button(action: action) {
                Image(systemName: "xmark.circle.fill")
                    .font(.title)
            }
            .buttonStyle(PlainButtonStyle())
        }
    }
}


